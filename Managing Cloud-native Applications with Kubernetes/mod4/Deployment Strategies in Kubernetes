<!-- ----------------------------------------------------------------------- -->
<!--                  strategies for updating applications                   -->
<!-- ----------------------------------------------------------------------- -->
strategies for updating applications deployed in a Kubernetes cluster. There are two main strategies discussed:

Rolling Strategy:

Updates are made gradually.
New pods are created for the updated version while the old pods remain until the new ones are ready to serve requests.
This ensures zero downtime during the update process.
Recreate Strategy:
All old pods are terminated at once before new pods are created.
This can lead to a period where no pods are available to serve requests, resulting in downtime.
This strategy is useful when the application cannot run multiple versions simultaneously.
The lecture also covers how to configure these strategies within the deployment specifications in Kubernetes, including parameters like maxSurge and maxUnavailable.

There are two main strategies for updating applications in Kubernetes:

Rolling Strategy: Updates are made gradually, allowing for zero downtime.
Recreate Strategy: All old pods are terminated at once before new pods are created, which may result in downtime.

<!-- ----------------------------------------------------------------------- -->
<!--                           real-life examples                            -->
<!-- ----------------------------------------------------------------------- -->

Example: Updating a Web Application

Scenario: Imagine you are a DevOps engineer working for an e-commerce company that has a web application serving thousands of customers daily. You need to update the application from Version 1 to Version 2 without causing downtime.

Rolling Strategy:

You decide to use the rolling update strategy.
As you deploy the new version, Kubernetes gradually replaces the old pods (Version 1) with new pods (Version 2).
For instance, if you have three replicas running Version 1, Kubernetes will:
Update Pod 1 to Version 2 while keeping Pods 2 and 3 running.
Once Pod 1 is confirmed to be ready and serving requests, Pod 2 is updated next.
This process continues until all pods are updated to Version 2.
Relevance: This strategy ensures that there is always at least one pod available to handle customer requests, resulting in zero downtime during the update.
Recreate Strategy:
In a different scenario, suppose the application has a significant change that does not support running both versions simultaneously (e.g., a major database schema change).
You opt for the recreate strategy.
When you deploy Version 2, Kubernetes immediately terminates all existing pods running Version 1.
After all old pods are destroyed, it starts creating new pods for Version 2.
Relevance: This approach may lead to a brief period where the application is not available to users, but it allows for a clean slate for the new version.

The rolling strategy is often preferred in production environments to maintain service availability, while the recreate strategy can be useful in specific situations where compatibility issues arise.

<!-- ----------------------------------------------------------------------- -->
<!--               pros and cons of each deployment strategy?                -->
<!-- ----------------------------------------------------------------------- -->
Here are the pros and cons of the two deployment strategies: rolling strategy and recreate strategy.

Rolling Strategy

Pros:

Zero Downtime: Ensures that at least some instances of the application are always available to handle requests during the update.
Gradual Rollout: Allows for monitoring of the new version's performance before fully committing to it, making it easier to roll back if issues arise.
User Experience: Provides a seamless experience for users, as they are less likely to notice any disruptions.
Cons:

Complexity: Requires the application to support running multiple versions simultaneously, which can complicate the architecture.
Resource Usage: Temporarily increases resource usage since both old and new versions run concurrently during the update.
State Management: Can be challenging if the application has shared state or persistent volumes that are not compatible with both versions.
Recreate Strategy

Pros:

Simplicity: Easier to implement since it does not require the application to support multiple versions running at the same time.
Clean Slate: Ensures that the new version starts with a fresh environment, which can be beneficial for major changes.
Faster Deployment: Can be quicker to execute since it involves stopping all old instances before starting new ones.
Cons:

Downtime: There is a period where the application is unavailable, which can negatively impact user experience and business operations.
Risk of Failure: If the new version has issues, there may be a complete service outage until the problem is resolved.
User Impact: Users may experience disruptions, especially during peak usage times, leading to potential loss of revenue or customer dissatisfaction.
Summary

Rolling Strategy is ideal for applications requiring high availability and minimal disruption, while Recreate Strategy is suitable for simpler deployments or when significant changes are made that do not support multiple versions.

<!-- ----------------------------------------------------------------------- -->
<!--                 configure maxSurge and maxUnavailable?                  -->
<!-- ----------------------------------------------------------------------- -->
maxSurge: This parameter specifies the maximum number of pods that can be created above the desired number of replicas during an update. It can be set as an absolute number or a percentage.
maxSurge: If set to 1, during an update, Kubernetes can create one additional pod beyond the desired replicas.

maxUnavailable: This parameter specifies the maximum number of pods that can be unavailable during the update process. Like maxSurge, it can also be set as an absolute number or a percentage.
maxUnavailable: If set to 1, at most one pod can be unavailable during the updat

<!-- ----------------------------------------------------------------------- -->
<!--           If both maxSurge and maxUnavailable are set to zero           -->
<!-- ----------------------------------------------------------------------- -->
If both maxSurge and maxUnavailable are set to zero in a Kubernetes deployment, the following will occur:

No Additional Pods: Setting maxSurge to zero means that during an update, Kubernetes will not create any additional pods beyond the desired number of replicas. This means that the number of running pods will remain constant during the update process.

No Unavailable Pods: Setting maxUnavailable to zero means that no pods can be unavailable during the update. This implies that all existing pods must remain operational and ready to serve requests throughout the update process.
Implications

No Downtime: While this configuration aims to prevent downtime, it can lead to a situation where the update cannot proceed if all existing pods must remain available and no new pods can be created.
Stuck Updates: If an update requires changes that necessitate the termination of existing pods (e.g., changing the container image), the deployment may become stuck, as Kubernetes cannot scale down any pods to make room for the new ones.
In summary, setting both maxSurge and maxUnavailable to zero can create a scenario where updates cannot be applied effectively, potentially leading to deployment issues.

<!-- --------------------------------------------------------------------------- -->
<!--  how k8s determines new pod is ready to receive requests in rolling update.-->
<!-- -------------------------------------------------------------------------- -->
Kubernetes determines when a new pod is ready to receive requests during a rolling update using readiness probes. Here’s how it works:

Readiness Probes: These are checks defined in the pod specification that determine if a pod is ready to handle traffic. You can configure different types of probes:

HTTP Probes: Kubernetes sends an HTTP request to a specified path and checks the response code.
TCP Probes: Kubernetes attempts to open a TCP connection to the specified port.
Exec Probes: Kubernetes runs a specified command inside the container and checks the exit status.
Configuration: You can configure readiness probes in the pod template of your deployment YAML file. For example:

readinessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
Pod Lifecycle: When a new pod is created during a rolling update:

Kubernetes starts the readiness probe checks based on the defined configuration.
If the probe succeeds (e.g., the HTTP response is 200), the pod is marked as "ready" and can start receiving traffic.
If the probe fails, the pod is not marked as ready, and traffic will not be routed to it.
Scaling Down Old Pods: Only after the new pod is marked as ready will Kubernetes scale down the old pod. This ensures that there is always at least one pod available to handle requests during the update process.
Summary

Readiness probes are essential for ensuring that new pods are fully operational before they start receiving traffic, allowing for a smooth transition during rolling updates.


<!-- ----------------------------------------------------------------------- -->
<!--                Blue-green deployment and A/B deployment.                -->
<!-- ----------------------------------------------------------------------- -->

Blue-green Deployment:

Involves two identical environments: Blue and Green.
Initially, the application runs on the Blue deployment.
When changes are made, they are deployed to the Green environment for testing.
Once confident, the ingress router is switched to direct traffic to the Green service, making it live.
The Blue deployment is then updated to match the Green deployment, preparing it for future changes.

A/B Deployment:

Involves routing requests to two different versions of the application (Version 1 and Version 2).
A portion of users receives Version 2 while most continue with Version 1.
This allows for monitoring and testing of the new version before fully rolling it out.
Once confident in Version 2, it can be scaled up while scaling down Version 1.
These strategies help manage application updates with minimal downtime and allow for effective testing and monitoring. 

<!-- ----------------------------------------------------------------------- -->
<!--          advantages of using routing strategies in Kubernetes?          -->
<!-- ----------------------------------------------------------------------- -->
Using routing strategies in Kubernetes offers several advantages:

Advantages of Routing Strategies:

Minimized Downtime: Routing strategies like Blue-green deployment allow for seamless transitions between application versions, reducing downtime during updates.

Testing in Production: A/B deployment enables testing of new features with a subset of users, allowing for real-world feedback without affecting the entire user base.

Risk Mitigation: By gradually rolling out changes, you can monitor performance and user engagement, making it easier to identify and address issues before a full deployment.

Easy Rollback: If a new version causes issues, reverting to the previous version is straightforward, as the routing can simply be switched back.

Improved User Experience: Users can benefit from new features without experiencing disruptions, leading to higher satisfaction.

Data-Driven Decisions: A/B testing provides valuable insights into user behavior, helping teams make informed decisions about which features to fully implement.
These advantages make routing strategies essential for managing cloud-native applications effectively.

<!-- ----------------------------------------------------------------------- -->
<!--                  implement A/B testing in Kubernetes?                   -->
<!-- ----------------------------------------------------------------------- -->
Implementing A/B testing in Kubernetes involves several steps to route traffic between different versions of your application. Here’s a simplified approach:

Steps to Implement A/B Testing in Kubernetes:

Deploy Multiple Versions:

Create two deployments in your Kubernetes cluster: one for Version 1 (A) and another for Version 2 (B).
Ensure both deployments are running and accessible.
Set Up a Service:

Create a Kubernetes Service that will route traffic to the different versions. This service can be configured to direct a percentage of traffic to each deployment.
Configure Ingress Controller:

Use an Ingress controller to manage external access to your services. You can define rules to route traffic based on specific criteria (e.g., headers, cookies).
Traffic Splitting:

Implement traffic splitting in your Ingress rules or service configuration. For example, you can route 80% of the traffic to Version 1 and 20% to Version 2.
Monitor Performance:

Use monitoring tools to track user engagement, performance metrics, and error rates for both versions. This data will help you assess which version performs better.
Adjust Traffic Distribution:

Based on the performance data, you can gradually increase the traffic to Version 2 if it performs well, or revert to Version 1 if issues arise.
Full Rollout:
Once confident in Version 2, you can switch all traffic to it and decommission Version 1.

<!-- ----------------------------------------------------------------------- -->
<!--                           real-life examples                            -->
<!-- ----------------------------------------------------------------------- -->
Real-Life Example: Online Retail Application Update

Scenario: Imagine you work as a systems engineer for an online retail company that frequently updates its website to improve user experience and add new features.

Blue-Green Deployment in Action:
Current State: Your online store is currently running on the "Blue" version of the application, which is stable and serving all customers.
Development of New Features: Your team has developed a new "Green" version of the application that includes a revamped checkout process and improved product recommendations.
Testing: Before making the Green version live, your team thoroughly tests it in the Kubernetes environment to ensure everything works as expected.
Switching Traffic: Once testing is complete and you're confident in the new features, you simply change the routing link from the Blue service to the Green service in your ingress router. Now, all users accessing the site are served by the new Green version.
Rollback Option: If any issues arise with the Green version, you can quickly switch back to the Blue version by changing the link again, ensuring minimal disruption to users.

Real-World Application: This example illustrates how companies can implement these strategies to enhance user experience while minimizing risks associated with deploying new features.

<!-- ----------------------------------------------------------------------- -->
<!--                             guided exercise                             -->
<!-- ----------------------------------------------------------------------- -->
explore deployment strategies for a Kubernetes cluster. The process involves:

Creating a Deployment: Using the kubectl command to create a deployment with a specified name and five replicas.
Understanding Update Strategies: The default update strategy is a rolling update, which allows for a maximum of 25% of pods to be unavailable during updates and a maximum surge of 25% more pods than the desired replicas.
Monitoring Pods: You will observe the behavior of pods during an update by editing the deployment to change the image version from 1-external to 2-external.
Pod Management: As the update occurs, Kubernetes manages the number of running pods, ensuring it does not exceed the surge limit while maintaining the desired number of replicas.
Finally, you will verify the application logs to confirm the update and clean up the deployment afterward.